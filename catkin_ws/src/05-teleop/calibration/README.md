# Package `calibration` {#calibration}

<move-here src='#pkg_name-autogenerated'/>

**TO DO**
⁻ Gracefully stop rosbag recording in compressed_image_to_world_frame.launch, so far requires hard-kill via CTRL+C.
- Bug in compressed_image_to_world_frame: see issues.

**REQUIRED**:

To be able to run the launch file: compressed_image_to_world_frame.launch:

use local_env.sh which sets the DUCKIEFLEET_ROOT to the default location. Make sure to include your calibration folder at DUCKIEFLEET_ROOT.

Install the lastest version of the scipy, as the code uses `ivp_solver` that is introduced in scipy version v1.2.0

This package is an automatic wheels calibration procedure.

- The launchfile commands.launch sends specific voltage command to the wheels while recording images with the camera in a rosbag.

- The launchfile calibration.launch calculates the different parameters of the theoretical model that fit best the trajectory of the Duckiebot.

- The launchfile test.launch tests if the calibration has succeed or not.


## Docker run command

docker -H 192.168.1.99 run -it --net host --privileged -v /data/logs:/logs -v /data:/data --memory="800m" --memory-swap="2.8g" --name base-dev-log_data selcukercan/rpi-duckiebot-base:base-dev2  /bin/bash
## Data Acquisition

### Logging to USB
It is recommended (or might be necessary depending on the free space available on your device) to use a USB for logging. Note that you have to run your container with `-v /data/logs:/logs`.

First plugging in the USB. SSH to your device and create this folder

```shell
sudo mkdir /data/logs
```
then mount it with:

```shell
sudo mount -t vfat /dev/sda1 /data/logs -o umask=000
```

After data-acquisition has been completed unmount the USB

```shell
sudo umount /data/logs
```

### Launching required processes  
Start camera-related functionality by roslaunching

```shell
roslaunch pi_camera cal_camera.launch veh:=![ROBOT_NAME] cam_param_file_name:=![PARAM_FILE]
```

Then start the data-acquisition interface by

```shell
roslaunch calibration data_collector.launch veh:=![ROBOT_NAME] output_rosbag_dir:=/logs
```
if `output_rosbag_dir` is not specified the program attempts to save the results to user´s home folder.

With this interface can specify

- the type of the experiment you would like to conduct by choosing amongst the presented options,

- whether to save the collected experiment data by answering the question after the experiment has been completed,

- whether to do another experiment.

Note that we can specify the resolution of the images taken with ´![PARAM_FILE]´. This file must be placed under

´/home/software/catkin_ws/src/00-infrastructure/duckietown/config/baseline/pi_camera/camera_node´



´$(duckietown)/config/baseline/pi_camera/camera_node´.

## Calibration  

### Processing Data

The data recorded during the experiment is /compressed_image, but calibration script requires /tag_detections_local_frame. To get a bag file with the correct topic.

```shell
roslaunch calibration compressed_image_to_world_frame.launch veh:=mete input_rosbag:=/home/selcuk/input.bag output_rosbag:=/home/selcuk/![OUTPUT_FILE_NAME].bag operation_mode:=1 custom_resolution:=![WIDTH_HEIGT_OF_IMAGE]
```

Note the `operation_mode` parameters which runs the image processing pipeline in sequential mode.

Also note if you choose to record the bag at a resolution that is different from the custom one (640, 480), you should pass the new resolution for (1440, 1080) as `1440_1080`.

Also note that image processing pipeline requires the calibration files to work correctly, currently the calibration files are look for in their default location, for instance intrinsic calibration file must be located at '![HOME_DIRECTORY]/duckiefleet/calibrations/camera_intrinsic/![ROBOT_NAME].yaml'.

### Optimization

On your local PC, start the optimization

```shell
roslaunch calibration calibration.launch veh:=![ROBOT_NAME] folder_path:=![INPUT_FOLDER_PATH] model:=![MODEL_NAME]
```

Note that the optimization script automatically loads and feeds all the bag files that are located inside ![INPUT_FOLDER_PATH]. To see all available models and their definition, refer to `PACKAGE_ROOT/include/calibration/model_library.py`.

## Transfer the calibration YAML files

```shell
scp /home/selcuk/duckiefleet/calibrations/kinematics/mete_kinematic_drive.yaml selcuk@mete:~/
sudo mv ~/mete_kinematic_drive.yaml /data/config/calibrations/kinematics/
```
## Test

Test script only contains a straight path test, and it automatically starts after roslaunch.

Run the test script with
```shell
roslaunch calibration test.launch veh:=![ROBOT_NAME] model:=![MODEL_NAME]
```

## Development Notes
## Pose estimation from Lane Filter

Develop offline by recording a bag by following the instructions above. Make sure bag contains compressed_image and cam_info. At this point, in case you use a different resolution than the custom one, the readings are expected to be off.

```shell
roslaunch calibration lane_pose.launch veh:=![ROBOT_NAME] local:=true
```

the program will not start until you play the bag, in a separate window

```shell
rosbag play --loop ROSBAG.bag
```

access the pose estiamtes through rostopic

```shell
rostopic echo /![ROBOT_NAME]/lane_filter_node/lane_pose
```

## Post-Processing the recorded bag

Remarks:

maximum allowed resolution to retain the default aspect ratio (4/3) is 1440 * 1080

## Only launching AprilTag detection

```shell
roslaunch pi_camera camera_apriltag_demo.launch veh:=![ROBOT_NAME]
```

```shell
roslaunch apriltags2_ros apriltag2_demo.launch veh:=![ROBOT_NAME]
```

## Launch Local pose detection

```shell
roslaunch apriltags2_ros detection_to_local_frame.launch veh:=![ROBOT_NAME]
```
